import pandas as pd
import lightgbm as lgb
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
import pickle
from lightgbm import callback

# 1. è¯»å–æ•°æ®
X_train = pd.read_csv("X_train.csv")
y_train = pd.read_csv("y_train.csv")
X_val = pd.read_csv("X_val.csv")
y_val = pd.read_csv("y_val.csv")

# 2. Quick Check Training Data
print("ğŸ” å¼€å§‹æ£€æŸ¥è®­ç»ƒæ•°æ®åŸºæœ¬ä¿¡æ¯...")
print(f"X_train shape: {X_train.shape}")
print(f"y_train shape: {y_train.shape}")

# æ ·æœ¬æ€»æ•°
print(f"è®­ç»ƒæ ·æœ¬æ€»æ•°: {len(y_train)}")

# æ­£è´Ÿæ ·æœ¬æ¯”ä¾‹
positive = (y_train.values.ravel() == 1).sum()
negative = (y_train.values.ravel() == 0).sum()
print(f"æ­£æ ·æœ¬æ•° (label=1): {positive}")
print(f"è´Ÿæ ·æœ¬æ•° (label=0): {negative}")
print(f"æ­£è´Ÿæ ·æœ¬æ¯”ä¾‹: {positive / (negative + 1e-9):.4f}")

# æ£€æŸ¥ç‰¹å¾æ˜¯å¦å¼‚å¸¸
print("\nğŸ” å¼€å§‹æ£€æŸ¥ç‰¹å¾å¼‚å¸¸...")
zero_variance_features = (X_train.std() == 0).sum()
print(f"æ ‡å‡†å·®ä¸º0çš„ç‰¹å¾æ•°é‡ï¼ˆæ— ç”¨ç‰¹å¾ï¼‰: {zero_variance_features}")

missing_values_features = (X_train.isnull().sum() > 0).sum()
print(f"å«æœ‰ç¼ºå¤±å€¼çš„ç‰¹å¾æ•°é‡: {missing_values_features}")

print("âœ… è®­ç»ƒæ•°æ®æ£€æŸ¥å®Œæ¯•ã€‚\n")

# 3. è½¬æ¢ä¸º LightGBM æ•°æ®æ ¼å¼
train_data = lgb.Dataset(X_train, label=y_train.values.ravel())
val_data = lgb.Dataset(X_val, label=y_val.values.ravel(), reference=train_data)

# 4. è®¾ç½® LightGBM è¶…å‚æ•°
params = {
    'objective': 'binary',
    'metric': 'binary_logloss',
    'boosting_type': 'gbdt',
    'num_leaves': 31,
    'learning_rate': 0.1,
    'feature_fraction': 0.9,
    'bagging_fraction': 0.8,
    'bagging_freq': 5,
    'verbose': -1,
    'scale_pos_weight': 2,
}

# 5. å®šä¹‰å›è°ƒå‡½æ•°
early_stopping_callback = callback.early_stopping(stopping_rounds=30)
log_callback = callback.log_evaluation(period=10)
evals_result = {}
record_eval_callback = callback.record_evaluation(evals_result)

# 6. è®­ç»ƒæ¨¡å‹
print("âœ… å¼€å§‹è®­ç»ƒ LightGBM æ¨¡å‹...")

model = lgb.train(
    params,
    train_data,
    valid_sets=[train_data, val_data],
    valid_names=['train', 'valid'],
    num_boost_round=2000,
    callbacks=[early_stopping_callback, log_callback, record_eval_callback]
)

# 7. è·å–æœ€ä½³è¿­ä»£æ¬¡æ•°
best_iteration = model.best_iteration
print(f"âœ… æœ€ä½³è¿­ä»£æ¬¡æ•°: {best_iteration}")

# 8. éªŒè¯é›†é¢„æµ‹
y_pred = model.predict(X_val, num_iteration=best_iteration)
y_pred_bin = (y_pred > 0.5).astype(int)

# 9. è¾“å‡ºè¯„ä¼°æŒ‡æ ‡
acc = accuracy_score(y_val, y_pred_bin)
precision = precision_score(y_val, y_pred_bin, zero_division=0)
recall = recall_score(y_val, y_pred_bin, zero_division=0)
f1 = f1_score(y_val, y_pred_bin, zero_division=0)

print(f"âœ… éªŒè¯é›†è¯„ä¼°ç»“æœï¼š")
print(f"Accuracy (å‡†ç¡®ç‡): {acc:.4f}")
print(f"Precision (ç²¾ç¡®ç‡): {precision:.4f}")
print(f"Recall (å¬å›ç‡): {recall:.4f}")
print(f"F1 Score: {f1:.4f}")

# 10. ä¿å­˜æ¨¡å‹
with open("lightgbm_model.pkl", "wb") as f:
    pickle.dump(model, f)

print("âœ… æ¨¡å‹è®­ç»ƒå®Œæˆå¹¶å·²ä¿å­˜ï¼šlightgbm_model.pkl")